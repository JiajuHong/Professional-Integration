# 5.2大数据的关键技术

## 1、大数据的架构

通常来说，在我们最终查看数据报表，或者使用数据进行算法预测之前，数据都会经历以下这么几个处理环节：

1. 数据采集：是指将应用程序产生的数据和日志等同步到大数据系统中。
2. 数据存储：海量的数据，需要存储在系统中，方便下次使用时进行查询。
3. 数据处理：原始数据需要经过层层过滤、拼接、转换才能最终应用，数据处理就是这些过程的统称。一般来说，有两种类型的数据处理，一种是<u>离线的批量处理</u>，另一种是<u>实时在线分析</u>。
4. 数据应用：经过处理的数据可以对外提供服务，比如生成可视化的报表、作为互动式分析的素材、提供给推荐系统训练模型等等。

![image-20221107143254335](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107143254335.png)

我们现在常用的大数据技术，其实都是基于Hadoop生态的。Hadoop是一个分布式系统基础架构，换言之，它的数据存储和加工过程都是分布式的，由多个机器共同完成。通过这样的并行处理，提高安全性和数据处理规模。

Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。我们可以把HDFS（Hadoop Distributed File System）理解为一套分布式的文件系统，大数据架构里的海量数据就是存储在这些文件里，我们每次分析，也都是从这些文件里取数。

而MapReduce则是一种分布式计算过程，它包括Map（映射）和Reduce（归约）。当你向MapReduce框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map任务，然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分，当Map任务完成后，Reduce会把前面若干个Map的输出汇总到一起并输出。相当于利用了分布式的机器，完成了大规模的计算任务。



### 数据采集

数据并不是天然就从Hadoop里生长出来，它往往存在于业务系统、外部文件里。当我们需要收集这些不同场景下的数据时，就需要用到各种不同的数据采集技术。这其中包括用于<u>数据库同步的Sqoop</u>，用于<u>采集业务日志的Flume</u>，还有用于<u>数据传输的Kafka</u>等等。

- 数据迁移：Sqoop是一个在<u>结构化数据</u>和Hadoop之间进行<u>批量数据迁移</u>的ETL工具，结构化数据可以是<u>MySQL、Oracle等RDBMS</u>。用户可以在 Sqoop 的帮助下，轻松地把关系型数据库的数据导入到 Hadoop 与其相关的系统 (如HBase和Hive)中；同时也可以把数据从 Hadoop 系统里抽取并导出到关系型数据库里。

- 日志采集：Flume是一个<u>分布式的海量日志采集系统</u>。支持在日志系统中定制各类数据发送方，并写到各种数据接受方的能力。它的基本结构如下，包含三个部分：数据收集组件Source，缓存Channel，保存Sink。多个Agent也可以组合使用。

  ![image-20221107143624938](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107143624938.png)

- 数据传输：Kafka是一个著名的<u>分布式消息队列</u>。通过它，数据的发送方和接收方可以准确、稳定的传输数据。它以可水平扩展，并支持高吞吐率。![image-20221107144235467](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107144235467.png)

  

  > 举个例子，生产者消费者，生产者生产鸡蛋，消费者消费鸡蛋，生产者生产一个鸡蛋，消费者就消费一个鸡蛋，假设消费者消费鸡蛋的时候噎住了（系统宕机了），生产者还在生产鸡蛋，那新生产的鸡蛋就丢失了。再比如生产者很强劲（大交易量的情况），生产者1秒钟生产100个鸡蛋，消费者1秒钟只能吃50个鸡蛋，那要不了一会，消费者就吃不消了（消息堵塞，最终导致系统超时），消费者拒绝再吃了，“鸡蛋”又丢失了，这个时候我们放个篮子在它们中间，生产出来的鸡蛋都放到篮子里，消费者去篮子里拿鸡蛋，这样鸡蛋就不会丢失了，都在篮子里，而这个篮子就是“kafka”。
  >
  > 鸡蛋其实就是“数据流”，系统之间的交互都是通过“数据流”来传输的（就是tcp、https什么的），也称为报文，也叫“消息”。
  >
  > 消息队列满了，其实就是篮子满了，”鸡蛋“ 放不下了，那赶紧多放几个篮子，其实就是kafka的扩容。

- 来自于Ftp/Http的数据源：
  有可能一些合作伙伴提供的数据，需要通过Ftp/Http等定时获取，DataX也可以满足该需求；
- 其他数据源：
  比如一些手工录入的数据，只需要提供一个接口或小程序，即可完成

### 数据存储

对结构化、半结构化、非结构化海量数据进行存储，存储到关系型数据库、非关系型数据库、数据仓库、分布式文件系统。

采集下来的数据需要保存到Hadoop里，从物理的角度看，它们保存为一个一个的HDFS文件。当然，除了HDFS以外，Hadoop还提供了一些配套工具，如便于实时处理数据的列族数据库Hbase，以及一个类似SQL的查询工具Hive，方便对HDFS数据进行查询。

- HDFS：在Hadoop里，底层的数据文件都存储在HDFS里，它是大数据的底层基础。HDFS容错率很高，即便是在系统崩溃的情况下，也能够在节点之间快速传输数据。
- Hbase：是一个高可靠性、高性能、面向列、可伸缩的分布式列族数据库，可以对大数据进行随机性的实时读取/写入访问。基于HDFS而建。
- Hive：是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。Hive通过元数据来描述Hdfs上的结构化文本数据，通俗点来说，就是定义一张表来描述HDFS上的结构化文本，包括各列数据名称，数据类型是什么等，方便我们处理数据，当前很多SQL ON Hadoop的计算引擎均用的是hive的元数据，如Spark SQL、Impala等。

### 数据处理

- 批数据处理：批处理是指一次批量的数据处理，它存在明确的开始和结束节点。常见的技术包括Hadoop自带的MapReduce，以及Spark。
  - MapReduce：如前文所说，通过Hadoop的MapReduce功能，可以将大的数据处理任务，拆分为分布式的计算任务，交给大量的机器处理，最终等处理完后拼接成我们需要的结果。这是一张批量处理的逻辑。
  - Spark：Spark是一个高速、通用大数据计算处理引擎。拥有Hadoop MapReduce所具有的优点，但不同的是Job的中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。
- 流数据处理：对于一些需要实时不间断处理的数据而言，等待MapReduce一次次缓慢加工，将文件反复保存到HDFS里并读取，显然太费时间了。一些新的流式数据处理工具被研发出来，它们的处理流程和批处理完全不同：
  - Spark Streaming：基于 Spark，另辟蹊径提出了 D-Stream（Discretized Streams）方案：将流数据切成很小的批（micro-batch），用一系列的短暂、无状态、确定性的批处理实现流处理。
  - Storm：是Twitter开源的分布式实时大数据处理框架，被业界称为实时版Hadoop。
  - Flink：可以理解为Storm的下一代解决方案，与HDFS完全兼容。Flink提供了基于Java和Scala的API，是一个高效、分布式的通用大数据分析引擎。更主要的是，Flink支持增量迭代计算，使得系统可以快速地处理数据密集型、迭代的任务。

大数据计算模式

![image-20221107150832240](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107150832240.png)

### 资源管理

在完成大数据处理任务的过程中，难免会涉及到多个任务、服务之间协调。这里面既包括资源的协调，也包括任务的协调。

- ZooKeeper：是一个分布式的，开放源码的分布式应用程序协调服务。假设我们的程序是分布式部署在多台机器上，如果我们要改变程序的配置文件，需要逐台机器去修改，非常麻烦，现在把这些配置全部放到zookeeper上去，保存在 zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 zookeeper 的通知，然后从 zookeeper 获取新的配置信息应用到系统中，以此保证各个程序的配置信息同步。
- Yarn：是一个<u>分布式资源调度器</u>组件。这个组件的主要作用是在每次接收到请求后，会查看当下的各个子节点的状况，统筹出运算资源的调度方案来保证任务可以顺利执行。通常来说，Yarn所调度的资源常常包括<u>磁盘空间的资源，内存的资源和通讯带宽的资源</u>等。

### **ETL任务管理**

- Kettle：这是一个ETL工具集，它允许你管理来自不同数据库的数据，通过提供一个图形化的界面来描述任务过程和彼此的依赖关系，以此来设定任务流程。

  ![image-20221107144948485](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107144948485.png)

- Azkaban：是一款基于Java编写的任务调度系统任务调度，来自LinkedIn公司，用于管理他们的Hadoop批处理工作流。Azkaban根据工作的依赖性进行排序，提供友好的Web用户界面来维护和跟踪用户的工作流程。

### 数据应用

#### 分析工具

数据处理完后，最终要想发挥价值，很重要的环节是进行分析和展示。很多工具都能提供分析支持，例如Kylin和Zeppelin。

- Kylin：是一个开源的分布式分析引擎，提供了基于Hadoop的超大型数据集（TB/PB级别）的SQL接口以及多维度的OLAP分布式联机分析。通过预先定义cube的方式，使得它能在亚秒内查询巨大的Hive表。
- Zeppelin：是一个提供交互数据分析且基于Web的笔记本。方便你做出可数据驱动的、可交互且可协作的精美文档，并且支持多种语言，包括 Scala(使用 Apache Spark)、Python(Apache Spark)、SparkSQL、 Hive、 Markdown、Shell等。

![image-20221107145055299](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107145055299.png)

#### 机器学习

除了分析外，大数据很重要的一个应用场景就是AI，借助于一些机器学习工具，大数据可以灵活的完成AI相关工作。

- Tensorflow：是Google开源的一款深度学习工具，它是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。在这个图中，节点（Nodes）表示数学操作，线（edges）表示在节点间相互联系的多维数据数组，即张量（tensor）。它配备了大量的机器学习相关API，能大幅提升机器学习的工作效率。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。
- Mahout：是一个算法库,集成了很多算法。旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包括许多实现，包括聚类、分类、推荐引擎、频繁子项挖掘等等。
- PyTorch是一个开源的Python机器学习库，基于Torch（英语：Torch (machine_learning)），底层由C++实现，应用于人工智能领域，如计算机视觉和自然语言处理。它主要由Meta Platforms的人工智能研究团队开发。著名的用途有：特斯拉自动驾驶，Uber最初发起而现属Linux基金会项目的概率编程软件Pyro，Lightning。

#### OLAP

[OLAP相关介绍](https://www.yijiyong.com/bigdata/oltpandolap/01-intro.html)

### 大数据技术架构图

#### Hadoop+Spark主流技术栈

![image-20221107150121923](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107150121923.png)

####  企业级大数据体系

![image-20221107150207105](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107150207105.png)

#### Google大数据技术栈

![image-20221107150259926](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107150259926.png)

####  Hadoop与Spark开源大数据技术栈

![image-20221107150330979](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107150330979.png)

***

![image-20221107150456037](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107150456037.png)

## 2、Hadoop

hadoop生态体系如下图所示

![image-20221107151210427](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107151210427.png)



### 何谓Hadoop？

我们生活在一个数据大爆炸的时代，数据飞快的增长，急需解决海量数据的存储和计算问题。

这个时候，Hadoop就应运而生了。

Hadoop是一个适合海量数据的分布式存储和分布式计算的框架。

- 分布式存储，可以简单理解为存储数据的时候，数据不只存在一台机器上面，它会存在多台机器上面。

- 分布式计算简单理解，就是由很多台机器并行处理数据，咱们在写java程序的时候，写的一般都是单机的程序，只在一台机器上运行，这样程序的处理能力是有限的。

### Hadoop的版本演变

目前Hadoop经历了3个版本演变。

![image-20221107151417171](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107151417171.png)

每一个大版本的升级都带来了一些质的提升，下面我们先从架构层面分析一下这三大版本的变更:

![image-20221107151511408](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107151511408.png)

从Hadoop1.x升级到Hadoop2.x，架构发生了比较大的变化，这里面的<u>HDFS是分布式存储</u>，<u>MapRecue是分布式计算</u>，咱们前面说了Hadoop解决了分布式存储和分布式计算的问题，对应的就是这两个模块

在Hadoop2.x的架构中，多了一个模块 YARN，这个是一个<u>负责资源管理的模块</u>，那在Hadoop1.x中就不需要进行资源管理吗？

也是需要的，只不过是<u>在Hadoop1.x中，分布式计算和资源管理都是MapReduce负责的</u>，从Hadoop2.x开始把资源管理单独拆分出来了，拆分出来的好处就是，YARN变成了一个公共的资源管理平台，在它上面不仅仅可以跑MapReduce程序，还可以跑很多其他的程序，只要你的程序满足YARN的规则即可

Hadoop的这一步棋走的是最好的，这样自己摇身一变就变成了一个公共的平台，由于它起步早，占有的市场份额也多，后期其它新兴起的计算框架一般都会支持在YARN上面运行，这样Hadoop就保证了自己的地位。

Hadoop3.x的架构并没有发生什么变化，但是它在其他细节方面做了很多优化。

#### Hadoop3.x的细节优化

在这里挑几个常见点说一下：

- 1：最低Java版本要求从Java7变为Java8

- 2：在Hadoop 3中，HDFS支持纠删码，纠删码是一种比副本存储更节省存储空间的数据持久化存储方法，使用这种方法，相同容错的情况下可以比之前节省一半的存储空间

  详细介绍在这里： https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html

- 3： Hadoop 2中的HDFS最多支持两个NameNode，一主一备，而Hadoop 3中的HDFS支持多个NameNode，一主多备

  详细介绍在这里： https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html

- 4：MapReduce任务级本地优化，MapReduce添加了映射输出收集器的本地化实现的支持。对于密集型的洗牌操作（shuffle-intensive）jobs，可以带来30%的性能提升，

  详细介绍在这里： https://issues.apache.org/jira/browse/MAPREDUCE-2841

- 5：修改了多重服务的默认端口，Hadoop2中一些服务的端口和Hadoop3中是不一样的

总结： Hadoop 3和2之间的主要区别在于新版本提供了更好的优化和可用性

详细的优化点也可以参考官网内容： https://hadoop.apache.org/docs/r3.0.0/index.html



### Hadoop的运行模式

#### 独立（本地）模式

独立模式无需任何守护进程，所有程序都在一个JVM上运行。主要用来学习或开发阶段调试用。

#### 伪分布模式

在本地机器上通过进程模拟出一个小规模的集群。

![image-20221107154710422](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107154710422.png)

#### 完全分布式

![image-20221107154800798](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107154800798.png)

### Hadoop三大核心组件

Hadoop其实就是一个统称，它里面包含了多个功能模块。

Hadoop主要包含三大组件：HDFS+MapReduce+YARN。

![image-20221107152034333](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107152034333.png)

#### HDFS

全称是Hadoop Distributed File System ，Hadoop的 分布式文件系统。HDFS负责海量数据的分布式存储，适合部署在廉价服务器上。

HDFS具有良好的扩展性、高容错性、适合PB级以上海量数据的存储的特点。

它是一种允许文件通过网络在多台主机上分享的文件系统，可以让多台机器上的多个用户分享文件和存储空间。

其实分布式文件管理系统有很多，HDFS只是其中一种实现而已。

还有 GFS(谷歌的)、TFS(淘宝的)、S3(亚马逊的)。

为什么会有多种分布式文件系统呢？这样不是重复造轮子吗？

不是的，因为不同的分布式文件系统的特点是不一样的，HDFS是一种适合大文件存储的分布式文件系统，不适合小文件存储，什么叫小文件，例如，几KB，几M的文件都可以认为是小文件。

##### HDFS体系结构

![image-20221107152657642](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107152657642.png)

HDFS支持主从结构，主节点称为 NameNode ，是因为主节点上运行的有NameNode进程，NameNode支持多个（2.0最多支持两个，3.0支持更多）。

从节点称为 DataNode ，是因为从节点上面运行的有DataNode进程，DataNode支持多个，由slaves文件决定。

HDFS中还包含一个 SecondaryNameNode 进程，这个进程从字面意思上看像是第二个NameNode的意思。

下图就是HDFS的体系结构，这里面的TCP、RPC、HTTP表示是不同的网络通信方式，这里集群NameNode和SecondaryNameNode进程是分开到多台机器中。

![image-20221107152956892](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107152956892.png)

- ### NameNode

  是整个文件系统的管理节点。

  它主要维护着整个文件系统的文件目录树，文件/目录的信息 和 每个文件对应的数据块列表，并且还负责接收用户的操作请求
  
  - 目录树：表示目录之间的层级关系，就是我们在hdfs上执行ls命令可以看到的那个目录结构信息。
  - 文件/目录的信息：表示文件/目录的的一些基本信息，所有者 属组 修改时间 文件大小等信息
  - 每个文件对应的数据块列表：如果一个文件太大，那么在集群中存储的时候会对文件进行切割，这个时候就类似于会给文件分成一块一块的，存储到不同机器上面。所以HDFS还要记录一下一个文件到底被分了多少块，每一块都在什么地方存储着。

  NameNode主要包括以下文件：
  
  ![image-20221107153121712](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107153121712.png)

这些文件所在的路径是由`hdfs-default.xml`的`dfs.namenode.name.dir`属性控制的。

```
fsimage: 元数据镜像文件，存储某一时刻NameNode内存中的元数据信息，就类似是定时做了一个快照操作。【这里的元数据信息是指文件目录树、文件/目录的信息、每个文件对应的数据块列表】

edits: 操作日志文件【事务文件】，这里面会实时记录用户的所有操作

seentxid: 是存放transactionId的文件，format之后是0，它代表的是namenode里面的edits*文件的尾数,namenode重启的时候，会按照seen_txid的数字，顺序从头跑edits_0000001~到seen_txid的数字。如果根据对应的seen_txid无法加载到对应的文件，NameNode进程将不会完成启动以保护数据一致性。

VERSION:保存了集群的版本信息。
```

- ### SecondaryNameNode

  SecondaryNameNode主要负责定期的把edits文件中的内容合并到fsimage中。

  这个合并操作称为checkpoint，在合并的时候会对edits中的内容进行转换，生成新的内容保存到fsimage文件中。

  <u>注意：在NameNode的HA架构中没有SecondaryNameNode进程，文件合并操作会由standby NameNode负责实现</u>

  所以在Hadoop集群中，SecondaryNameNode进程并不是必须的。

- ### DataNode

  DataNode是提供真实文件数据的存储服务。

  针对datanode主要掌握两个概念，一个是block，一个是replication。

  首先是block。

  HDFS会按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block，HDFS默认Block大小是 128MB。

  Blokc块是HDFS读写数据的基本单位，不管你的文件是文本文件 还是视频 或者音频文件，针对hdfs而言 都是字节。

  > HDFS中，如果一个文件小于一个数据块的大小，那么并不会占用整个数据块的存储空间.

![image-20221107153604339](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/13837/image-20221107153604339.png)

​		replication是文件的副本数，是在hdfs-site.xml中进行配置的。默认副本数是3.修改副本数后，原先文件的副本数并不·不会随之		改变。



#### MapReduce

Hadoop MapReduce是一个使用简易的<u>分布式并行计算框架</u>，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集。

MapReduce采用“分而治之”的思想。一个MapReduce *作业（job）* 通常会把输入的数据集切分为若干独立的数据块，由 *map任务（task）*以完全并行的方式处理它们。框架会对map的输出先进行排序， 然后把结果输入给*reduce任务*。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。

通常，MapReduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，<u>计算节点和存储节点通常在一起</u>。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。

MapReduce框架由一个单独的<u>master （JobTracker）</u> 和每个集群节点一个<u>slave （TaskTracker）</u>共同组成。master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上，master监控它们的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务。

应用程序至少应该指明输入/输出的位置（路径），并通过实现合适的接口或抽象类提供map和reduce函数。再加上其他作业的参数，就构成了*作业配置（job configuration）*。然后，Hadoop的 *job client*提交作业（jar包/可执行程序等）和配置信息给JobTracker，后者负责分发这些软件和配置信息给slave、调度任务并监控它们的执行，同时提供状态和诊断信息给job-client。

> 虽然Hadoop框架是用Java实现的，但Map/Reduce应用程序则不一定要用 Java来写 。

[]: https://www.itheima.com/news/20210415/141213.html	"MapReduce工作流程"
[]: hadoop笔记4--MapReduce框架	"hadoop笔记4--MapReduce框架"

MR的基本功能：

1. 数据划分和计算任务调度
2. 数据/代码互定位：从数据所在的本地机架上寻找可用节点以减少通信延迟。
3. 系统优化：Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。减少数据通信开销。
4. 出错监测和恢复：监测并隔离处出错节点，并调度分配新的节点接管出错节点的计算任务。

#### Yarn

[]: https://blog.csdn.net/a755199443/article/details/101381503	"Yarn工作流程"



## 3、NoSQL技术

NoSQL数据库是非关系型数据库，它主要用来存储半结构化数据和非结构化数据。它的数据存储格式可以是松散的、通常不支持Join操作并且易于横向扩展。

主流的NoSQL数据库有：Redis、MongoDB、Hbase。

NoSQL技术功能：

1. 数据管理：提供查询窗口和命令窗口
2. 结构管理：提供库、文档和索引等对象管理
3. 实时性管理：核心指标的实时展示

NoSQL优点：

拓展简单、读写快速、成本低廉、数据模型灵活

NoSQL缺点：不提供SQL支持、支持的特性不够丰富、现有的产品不够成熟

NoSQL四大类型：

1. 键值数据库：具有高并发性。Redis。
2. 多值（列族）数据库：分布式数据库，提供一个访问多种数据库的公共接口。
3. 文档数据库：以文档为存储信息,MongoDB、BaseX、CouchDB
4. 图形数据库：将点、线、面按照一定数据结构进行存储，FlockDB、Neo4j



### Hbase

Hbase是一个分布式、面向列的数据库。适合存储非结构化数据。



## 4、爬虫技术

网络爬虫是按一定规则、自动抓取万维网信息的脚本或程序。

### 爬虫的分类

按照使用场景分为两类

1. 通用爬虫：是 捜索引擎抓取系统（Baidu、Google、Yahoo等）的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。
2. 聚焦爬虫：是"面向特定主题需求"的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于： 聚焦爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息。

按系统结构和实现技术分为4类

1. 通用网络爬虫

   全网网络爬虫，由部分种子URL扩展到整个网络的全部页面，主要应用于搜索引擎。

2. 聚焦网络爬虫

   主题网络爬虫，是指选择性的采集那些预先定义好的主题相关的页面。

3. 增量网络爬虫

   是指对已下载网页采取增量式更新，只采集新产生的或发生改变的网页。

4. 深度网络爬虫

   Deep Web爬虫。是指对大部分内容不能通过静态链接获取，只有用户提交表单信息才能获取web页面的爬虫。

### 爬虫软件的分类

1. 云采集器（不需要按照软件）
2. 采集器（下载安装相应软件）

常用工具：神箭手云爬虫、八爪鱼采集器、集搜客GooSeeker、WebMagic、DenseSpider

## 5、清洗技术

去除脏数据（有错误或互相之间有冲突的数据）。包含对数据的一致性、无效值、缺失值、重复值等多方面的检查。

ETL（Extract/Transformation/Load）清洗/转换/加载。用户从数据源抽取所需的数据，经过清洗、转换，最终按照预先定义好的数仓模型，加载到数仓中。

常用工具：DataWrangler、Google Refine

## 6、大数据分析

从数据中提取信息，研究对象的内在规律。

常见大数据分析方法：

1. 漏斗分析法
2. 对比分析法
3. 用户分析法
4. 细分分析法
5. 指标分析法

大数据分析主要针对两个方面：

1. 规模非常庞大的结构化数据和半结构化数据。
2. 对非结构化数据进行分析。

## 7、大数据挖掘

数据挖掘是从大量的、不完全的、有噪声的、模糊的、随机的实际数据中，提取隐含在其中的、人们不知道的但是有潜在有用信息和知识（可接收、可理解、可运用）的过程。

从广义上说，任何从数据里面挖掘出有用信息的过程都叫数据挖掘。

从狭义上说，数据挖掘是从特定形式的数据集中提炼知识的过程。数据挖掘往往针对特定的数据、特定的问题，选择一种或多种挖掘算法，找到数据下面隐藏的规律，来预测、支持决策。

为了将数据转化为知识，常常需要利用数据仓库、OLAP、和数据挖掘等技术。从技术层面讲，数据挖掘不是新技术，而是这些技术的总和运用。

### 数据挖掘方法

1. 机器学习：神经网络、决策树、SVM（支持向量机）、深度学习
2. 统计方法：回归分析（多元回归）、判别分析（贝叶斯判别）、聚类分析（动态聚类）
3. 数据库方法：SQL、OLAP（联机分析处理）



## 8、大数据可视化

数据可视化是以图形或图表的形式展示数据。数据可视化后可以更加直观的帮助人们快速理解数据，发现









